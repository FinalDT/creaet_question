# -*- coding: utf-8 -*-
"""
RAG ê¸°ë°˜ ê°œì¸í™” ë¬¸ì œ ìƒì„± ì„œë¹„ìŠ¤
ì •ë‹µë¥  ê¸°ë°˜ Top-3 ê°œë… ì„ íƒ í›„ 6ê°œ ë¬¸ì œ ìƒì„±
"""
import logging
import json
import azure.functions as func
from ..core.database import get_sql_connection, get_question_data, get_mapped_concept_name, get_knowledge_tag_by_concept
from ..core.ai_service import get_openai_client, generate_question_with_ai
from ..core.validation import validate_question_format, prepare_question_record, prepare_answer_record
from ..core.utils import generate_question_id, get_grade_international
from ..core.responses import create_success_response, create_error_response


def create_cors_headers():
    """CORS í—¤ë” ìƒì„± (3000í¬íŠ¸ë§Œ í—ˆìš©)"""
    return {
        "Content-Type": "application/json; charset=utf-8",
        "Access-Control-Allow-Origin": "http://localhost:3000",
        "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
        "Access-Control-Allow-Headers": "Content-Type, Authorization"
    }


def extract_primary_chapter(chapter_name):
    """chapter_nameì—ì„œ ì²« ë²ˆì§¸ ì£¼ì œ ì¶”ì¶œ
    ì˜ˆ: 'ì´ì°¨ë°©ì •ì‹ > ì´ì°¨ë°©ì •ì‹ > ì œê³±ê·¼ì„ ì´ìš©í•œ ì´ì°¨ë°©ì •ì‹ì˜ í’€ì´' â†’ 'ì´ì°¨ë°©ì •ì‹'
    """
    if not chapter_name:
        return chapter_name

    # '>' êµ¬ë¶„ìë¡œ ë¶„ë¦¬í•˜ì—¬ ì²« ë²ˆì§¸ ë¶€ë¶„ ì¶”ì¶œ
    parts = chapter_name.split('>')
    return parts[0].strip() if parts else chapter_name


def get_concept_difficulty_band(concept_name):
    """ê°œë…ëª… ê¸°ë°˜ ë‚œì´ë„ íŒë‹¨ (ì„ì‹œ í•´ê²°ì±…)"""
    if not concept_name:
        return "ì¤‘"
    
    concept_lower = concept_name.lower()
    
    # ê³ ë‚œì´ë„ ê°œë… í‚¤ì›Œë“œ
    high_difficulty_keywords = [
        'ì´ì°¨ë°©ì •ì‹', 'ì´ì°¨í•¨ìˆ˜', 'ì‚¼ê°í•¨ìˆ˜', 'ë¯¸ë¶„', 'ì ë¶„', 'í™•ë¥ ê³¼í†µê³„',
        'ë²¡í„°', 'í–‰ë ¬', 'ê·¹í•œ', 'ë¡œê·¸', 'ì§€ìˆ˜', 'ì‚¼ê°ë¹„', 'ì›ì˜ë°©ì •ì‹',
        'í¬ë¬¼ì„ ', 'íƒ€ì›', 'ìŒê³¡ì„ ', 'ê³µê°„ë„í˜•', 'ì…ì²´ë„í˜•', 'íšŒì „ì²´',
        'ì¡°í•©', 'ìˆœì—´', 'ì´í•­ì •ë¦¬', 'í™•ë¥ ë¶„í¬', 'ì •ê·œë¶„í¬'
    ]
    
    # ì €ë‚œì´ë„ ê°œë… í‚¤ì›Œë“œ  
    low_difficulty_keywords = [
        'ìì—°ìˆ˜', 'ì •ìˆ˜', 'ìœ ë¦¬ìˆ˜', 'ë¬´ë¦¬ìˆ˜', 'ì†Œìˆ˜', 'ë¶„ìˆ˜',
        'ë§ì…ˆ', 'ëº„ì…ˆ', 'ê³±ì…ˆ', 'ë‚˜ëˆ—ì…ˆ', 'ì‚¬ì¹™ì—°ì‚°', 'ê³„ì‚°',
        'ê¸°ë³¸ë„í˜•', 'ì ', 'ì„ ', 'ë©´', 'ê°', 'ì§ì„ ', 'ë°˜ì§ì„ ', 'ì„ ë¶„',
        'ì›', 'ì‚¼ê°í˜•', 'ì‚¬ê°í˜•', 'ë‹¤ê°í˜•', 'ëŒ€ì¹­', 'ì´ë™',
        'í‘œ', 'ê·¸ë˜í”„', 'ë§‰ëŒ€ê·¸ë˜í”„', 'ì›ê·¸ë˜í”„', 'í‰ê· ', 'ì¤‘ì•™ê°’'
    ]
    
    # ê³ ë‚œì´ë„ ì²´í¬
    for keyword in high_difficulty_keywords:
        if keyword in concept_lower:
            return "ìƒ"
    
    # ì €ë‚œì´ë„ ì²´í¬
    for keyword in low_difficulty_keywords:
        if keyword in concept_lower:
            return "í•˜"
    
    # ê¸°ë³¸ê°’ (ì¤‘ê°„ ë‚œì´ë„)
    return "ì¤‘"


def get_top_concepts_by_accuracy(grade, top_k=3):
    """ì •ë‹µë¥  ê¸°ë°˜ìœ¼ë¡œ Top-K ê°œë… ì„ íƒ (chapter_name ì²« ë²ˆì§¸ ë¶€ë¶„ ê¸°ì¤€)"""
    try:
        print(f"      Connecting to database...")
        conn = get_sql_connection()
        if not conn:
            print(f"      Database connection failed!")
            return None

        cursor = conn.cursor()
        print(f"      Executing query for grade={grade} (all terms)...")

        # 1ë‹¨ê³„: ì „ì²´ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM gold.vw_personal_item_enriched")
        total_count = cursor.fetchone()[0]
        print(f"      Total records in view: {total_count}")

        # 2ë‹¨ê³„: grade=8 ë°ì´í„° í™•ì¸
        cursor.execute(f"SELECT COUNT(*) FROM gold.vw_personal_item_enriched WHERE grade = {grade}")
        grade_count = cursor.fetchone()[0]
        print(f"      Grade {grade} records: {grade_count}")

        # 3ë‹¨ê³„: ìƒ˜í”Œ ë°ì´í„° í™•ì¸ (concept_name ëª…ì‹œì  ìºìŠ¤íŒ…)
        if grade_count > 0:
            try:
                cursor.execute(f"SELECT TOP 3 CAST(concept_name AS NVARCHAR(MAX)) as concept_name, is_correct FROM gold.vw_personal_item_enriched WHERE grade = {grade}")
                sample_data = cursor.fetchall()
                print(f"      Sample data:")
                for i, (concept, is_correct) in enumerate(sample_data):
                    print(f"         {i+1}. {concept} | is_correct: {is_correct}")
            except Exception as e:
                print(f"      Sample data query failed: {str(e)}")

        # 4ë‹¨ê³„: ë©”ì¸ ì¿¼ë¦¬ ì‹¤í–‰ (nvarchar ëª…ì‹œì  ìºìŠ¤íŒ…)
        try:
            query = f"""
                WITH primary_chapters AS (
                    SELECT
                        CASE
                            WHEN CHARINDEX('>', CAST(chapter_name AS NVARCHAR(MAX))) > 0
                            THEN LTRIM(RTRIM(SUBSTRING(CAST(chapter_name AS NVARCHAR(MAX)), 1, CHARINDEX('>', CAST(chapter_name AS NVARCHAR(MAX))) - 1)))
                            ELSE CAST(chapter_name AS NVARCHAR(MAX))
                        END as primary_chapter,
                        CAST(is_correct AS FLOAT) as is_correct
                    FROM gold.vw_personal_item_enriched
                    WHERE grade = {grade}
                )
                SELECT
                    primary_chapter,
                    AVG(is_correct) as avg_correct_rate,
                    COUNT(*) as item_count
                FROM primary_chapters
                WHERE primary_chapter IS NOT NULL AND primary_chapter != ''
                GROUP BY primary_chapter
                HAVING COUNT(*) >= 1
                ORDER BY ABS(AVG(is_correct) - 0.625) ASC
            """
            print(f"      Executing main query (with NVARCHAR casting)...")

            cursor.execute(query)
            results = cursor.fetchall()
            print(f"      Raw query results: {len(results)} rows")

            if results:
                print(f"      Sample results (first 3):")
                for i, result in enumerate(results[:3]):
                    print(f"         {i+1}. {result[0]} (rate: {result[1]:.3f}, count: {result[2]})")

            conn.close()

            if results:
                concepts = []
                for result in results:
                    concepts.append({
                        'primary_chapter': result[0],  # chapter_name ì²« ë²ˆì§¸ ë¶€ë¶„
                        'avg_correct_rate': result[1],
                        'item_count': result[2]
                    })

                # Top-K ê°œë… ë°˜í™˜
                return concepts[:top_k] if len(concepts) >= top_k else concepts

            return []

        except Exception as e:
            print(f"      Main query failed: {str(e)}")
            conn.close()
            return []

    except Exception as e:
        logging.error(f"Error getting top concepts by accuracy: {str(e)}")
        return None


def get_assessment_ids_by_concepts(concepts, target_count=6):
    """ê°œë…ë³„ assessmentItemID ìˆ˜ì§‘ ë° 6ê°œ í™•ì •"""
    try:
        conn = get_sql_connection()
        if not conn:
            return None

        cursor = conn.cursor()
        all_ids = []

        # ê° primary chapterë³„ ID ìˆ˜ì§‘
        for concept in concepts:
            primary_chapter = concept['primary_chapter']

            # chapter_nameì´ í•´ë‹¹ primary chapterë¡œ ì‹œì‘í•˜ëŠ” ë ˆì½”ë“œë“¤ ì¡°íšŒ
            cursor.execute("""
                SELECT DISTINCT
                    assessmentItemID,
                    concept_name,
                    grade,
                    term,
                    chapter_name
                FROM gold.vw_personal_item_enriched
                WHERE grade = 8
                  AND (
                      CAST(chapter_name AS NVARCHAR(MAX)) LIKE ? + ' > %'
                      OR CAST(chapter_name AS NVARCHAR(MAX)) = ?
                  )
                ORDER BY assessmentItemID
            """, (primary_chapter, primary_chapter))

            results = cursor.fetchall()

            for result in results:
                all_ids.append({
                    'assessment_item_id': result[0],
                    'concept_name': result[1],
                    'grade': result[2],
                    'term': result[3],
                    'chapter_name': result[4]
                })

        conn.close()

        # ID ê°œìˆ˜ ì¡°ì •
        if len(all_ids) == target_count:
            # ë”± ë§ëŠ” ê²½ìš°
            return all_ids
        elif len(all_ids) < target_count:
            # ë¶€ì¡±í•œ ê²½ìš° - ì¶”ê°€ ê°œë…ì—ì„œ ë³´ì¶©
            return get_additional_ids(all_ids, target_count - len(all_ids))
        else:
            # ì´ˆê³¼í•˜ëŠ” ê²½ìš° - ê° ê°œë…ë³„ ê· ë“± ìƒ˜í”Œë§
            return balance_ids_by_concept(all_ids, target_count)

    except Exception as e:
        logging.error(f"Error getting assessment IDs by concepts: {str(e)}")
        return None


def get_additional_ids(existing_ids, needed_count):
    """ë¶€ì¡±ë¶„ì„ í•˜ìœ„ ê°œë…ì—ì„œ ë³´ì¶©"""
    try:
        conn = get_sql_connection()
        if not conn:
            return existing_ids

        cursor = conn.cursor()

        # ì´ë¯¸ ì‚¬ìš©ëœ ê°œë… ì œì™¸
        used_concepts = set(item['concept_name'] for item in existing_ids)
        concept_filter = "'" + "','".join(used_concepts) + "'" if used_concepts else "''"

        # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 2í•™ë…„ ì „ì²´ (í•™ê¸° ì¡°ê±´ ì œê±°), í•˜ìœ„ ìˆœìœ„ ê°œë…ì—ì„œ í•„ìš”í•œ ë§Œí¼ ê°€ì ¸ì˜¤ê¸°
        cursor.execute(f"""
            SELECT TOP {needed_count}
                assessmentItemID,
                concept_name,
                grade,
                term,
                chapter_name
            FROM gold.vw_personal_item_enriched
            WHERE grade = 8
            AND concept_name NOT IN ({concept_filter})
            ORDER BY assessmentItemID
        """)

        results = cursor.fetchall()
        conn.close()

        for result in results:
            existing_ids.append({
                'assessment_item_id': result[0],
                'concept_name': result[1],
                'grade': result[2],
                'term': result[3],
                'chapter_name': result[4]
            })

        return existing_ids

    except Exception as e:
        logging.error(f"Error getting additional IDs: {str(e)}")
        return existing_ids


def balance_ids_by_concept(all_ids, target_count):
    """ê°œë…ë³„ ê· ë“± ìƒ˜í”Œë§ìœ¼ë¡œ 6ê°œ ë§ì¶¤"""
    from collections import defaultdict
    import math

    # ê°œë…ë³„ ê·¸ë£¹í™”
    concept_groups = defaultdict(list)
    for item in all_ids:
        concept_groups[item['concept_name']].append(item)

    balanced_ids = []
    concepts = list(concept_groups.keys())
    items_per_concept = target_count // len(concepts)
    remaining = target_count % len(concepts)

    for i, concept in enumerate(concepts):
        concept_items = concept_groups[concept]

        # ê° ê°œë…ë³„ í• ë‹¹ëŸ‰ ê³„ì‚°
        take_count = items_per_concept
        if i < remaining:  # ë‚˜ë¨¸ì§€ë¥¼ ì•ìª½ ê°œë…ë“¤ì— ë¶„ë°°
            take_count += 1

        # í•´ë‹¹ ê°œë…ì—ì„œ í•„ìš”í•œ ë§Œí¼ ì„ íƒ
        balanced_ids.extend(concept_items[:take_count])

        if len(balanced_ids) >= target_count:
            break

    return balanced_ids[:target_count]


def find_matching_assessment_id(question, assessment_items):
    """ìƒì„±ëœ ë¬¸ì œì˜ ì£¼ì œì— ë§ëŠ” assessmentItemID ì°¾ê¸°"""
    question_text = question.get('question_text', '').lower()

    # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
    concept_keywords = {
        'ì´ì°¨ë°©ì •ì‹': ['ì´ì°¨ë°©ì •ì‹', 'xÂ²', 'x^2', 'ê·¼', 'í•´'],
        'í‰í–‰ì‚¬ë³€í˜•': ['í‰í–‰ì‚¬ë³€í˜•', 'í‰í–‰ì„ ', 'ëŒ€ê°'],
        'ìœ í•œì†Œìˆ˜': ['ì†Œìˆ˜', 'ë¶„ìˆ˜', '0.', 'ìœ í•œ'],
        'ì—°ë¦½ë°©ì •ì‹': ['ì—°ë¦½', 'ë°©ì •ì‹', '{', '}'],
        'ì‚¼ê°í˜•': ['ì‚¼ê°í˜•', 'ì™¸ì‹¬', 'ë‚´ì‹¬', 'ê°'],
        'ì¼ì°¨í•¨ìˆ˜': ['ì¼ì°¨í•¨ìˆ˜', 'y =', 'xì¶•', 'yì¶•', 'ê·¸ë˜í”„']
    }

    # ê° assessment_itemê³¼ ë§¤ì¹­ ì‹œë„
    for item in assessment_items:
        concept_name = item['concept_name']

        # concept_nameê³¼ ì§ì ‘ ë¹„êµ
        if any(keyword in question_text for keyword in concept_keywords.get(concept_name.split()[0], [])):
            return item['assessment_item_id']

    # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì²«ë²ˆì§¸ í•­ëª© ë°˜í™˜ (fallback)
    return assessment_items[0]['assessment_item_id'] if assessment_items else generate_question_id()


def create_rag_context_block(assessment_items):
    """RAG ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡ ìƒì„±"""
    context_lines = ["ë¶ˆë³€ ëª©ë¡ (ê° í–‰ë‹¹ ì •í™•íˆ 1ë¬¸í•­ ìƒì„±):"]

    for i, item in enumerate(assessment_items, 1):
        # difficulty_bandê°€ ì—†ê±°ë‚˜ NULLì¸ ê²½ìš° ê°œë… ê¸°ë°˜ ë‚œì´ë„ í• ë‹¹
        db_difficulty = item.get('difficulty_band')
        if not db_difficulty or db_difficulty == 'ì¤‘':
            difficulty_band = get_concept_difficulty_band(item['concept_name'])
        else:
            difficulty_band = db_difficulty
            
        line = f"[{i}] ID={item['assessment_item_id']}, concept={item['concept_name']}, chapter={item['chapter_name']}, grade=ì¤‘{item['grade']-6}, term={item['term']}í•™ê¸°, difficulty={difficulty_band}"
        context_lines.append(line)

    context_lines.extend([
        "",
        "ì •ì±… (í•„ìˆ˜ ì¤€ìˆ˜):",
        "- ê° í–‰ë‹¹ ì •í™•íˆ 1ë¬¸í•­, ë™ì¼ ID/ë™ì¼ ì£¼ì œ ìœ ì§€",
        "- ê°ê´€ì‹ 4ì§€, í•œêµ­ì–´, LaTeX í—ˆìš©",
        "- assessmentItemIDì™€ concept_name ë³€ê²½ ê¸ˆì§€",
        "- ê°œë… ë°– ì§€ì‹ ì‚¬ìš© ê¸ˆì§€, ê·¼ê±° ë¶€ì¡± ì‹œ í•´ë‹¹ í–‰ì€ skip:true",
        "- ë‚œì´ë„ëŠ” difficulty ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì ì ˆí•œ ìˆ˜ì¤€ìœ¼ë¡œ ìƒì„± (ìƒ/ì¤‘/í•˜)",
        "- 6ê°œë¥¼ í•œ ë²ˆì— JSON ë°°ì—´ë¡œ ë°˜í™˜ (ê¸¸ì´ 6, skip í¬í•¨ ê°€ëŠ¥)"
    ])

    return "\n".join(context_lines)


def handle_rag_personalized_generation(req):
    """RAG ê¸°ë°˜ ê°œì¸í™” ë¬¸ì œ ìƒì„± ì²˜ë¦¬"""
    logging.info('RAG personalized question generation API called')

    try:
        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ë°›ì€ í•™ë…„ íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        grade_param = None
        
        # GET ìš”ì²­: URL íŒŒë¼ë¯¸í„°ì—ì„œ ì¶”ì¶œ
        if req.method == "GET":
            grade_param = req.params.get('grade')
        # POST ìš”ì²­: JSON body ë˜ëŠ” URL íŒŒë¼ë¯¸í„°ì—ì„œ ì¶”ì¶œ
        elif req.method == "POST":
            try:
                req_body = req.get_json()
                if req_body and 'grade' in req_body:
                    grade_param = req_body.get('grade')
                else:
                    grade_param = req.params.get('grade')
            except:
                grade_param = req.params.get('grade')
        
        # í•™ë…„ íŒŒë¼ë¯¸í„° ê²€ì¦
        if not grade_param:
            response_data = create_error_response(
                "í•™ë…„ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜ˆ: ?grade=2",
                status_code=400
            )
            return func.HttpResponse(
                json.dumps(response_data, ensure_ascii=False),
                status_code=400,
                headers=create_cors_headers()
            )
        
        try:
            grade_korean = int(grade_param)
        except ValueError:
            response_data = create_error_response(
                "í•™ë…„ì€ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤. ì§€ì› í•™ë…„: 1, 2, 3 (ì¤‘í•™êµ)",
                status_code=400
            )
            return func.HttpResponse(
                json.dumps(response_data, ensure_ascii=False),
                status_code=400,
                headers=create_cors_headers()
            )
        
        # í•™ë…„ ë²”ìœ„ ê²€ì¦ (ì¤‘í•™êµ 1-3í•™ë…„)
        if grade_korean not in [1, 2, 3]:
            response_data = create_error_response(
                "ì§€ì›ë˜ì§€ ì•ŠëŠ” í•™ë…„ì…ë‹ˆë‹¤. ì§€ì› í•™ë…„: 1, 2, 3 (ì¤‘í•™êµ)",
                status_code=400
            )
            return func.HttpResponse(
                json.dumps(response_data, ensure_ascii=False),
                status_code=400,
                headers=create_cors_headers()
            )
        
        # í•œêµ­ì‹ í•™ë…„ â†’ êµ­ì œì‹ í•™ë…„ ë³€í™˜ (1,2,3 â†’ 7,8,9)
        grade = grade_korean + 6
        
        print(f"\n[RAG Process Start] Grade {grade} (ì¤‘í•™êµ {grade_korean}í•™ë…„, All Terms)")
        print(f"[Step 1] Retrieval - Concept Selection by Accuracy")
        logging.info(f"Using parameters: korean_grade={grade_korean}, international_grade={grade}")

        # 1ë‹¨ê³„: ì •ë‹µë¥  ê¸°ë°˜ Top-3 ê°œë… ì„ íƒ
        print(f"   Querying database for concepts...")
        top_concepts = get_top_concepts_by_accuracy(grade, top_k=3)

        print(f"   Database query result: {len(top_concepts) if top_concepts else 0} concepts found")
        if top_concepts:
            print(f"   Found concepts: {[c['primary_chapter'] for c in top_concepts]}")
        else:
            print(f"   No concepts found - checking database connection and data...")

        if not top_concepts:
            response_data = create_error_response(
                f"ì¤‘í•™êµ {grade_korean}í•™ë…„ì— ëŒ€í•œ í•™ìŠµ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í•™ë…„ì„ ì‹œë„í•´ë³´ì„¸ìš”. (ì§€ì› í•™ë…„: 1, 2, 3)",
                status_code=404
            )
            return func.HttpResponse(
                json.dumps(response_data, ensure_ascii=False),
                status_code=404,
                headers=create_cors_headers()
            )

        print(f"   Selected concepts ({len(top_concepts)} found):")
        for i, concept in enumerate(top_concepts, 1):
            print(f"      {i}. {concept['primary_chapter']} (accuracy: {concept['avg_correct_rate']:.3f})")
        logging.info(f"Selected top concepts: {[c['primary_chapter'] for c in top_concepts]}")

        print(f"[Step 2] Assessment ID Collection (Target: 6 IDs)")
        # 2ë‹¨ê³„: ê° ê°œë…ë³„ assessmentItemID ìˆ˜ì§‘ ë° 6ê°œ í™•ì •
        assessment_items = get_assessment_ids_by_concepts(top_concepts, target_count=6)
        if not assessment_items or len(assessment_items) == 0:
            response_data = create_error_response(
                f"ì¤‘í•™êµ {grade_korean}í•™ë…„ì˜ ë¬¸ì œ ìƒì„± ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í•™ë…„ì„ ì‹œë„í•´ë³´ì„¸ìš”.",
                status_code=404
            )
            return func.HttpResponse(
                json.dumps(response_data, ensure_ascii=False),
                status_code=404,
                headers=create_cors_headers()
            )

        print(f"   â””â”€ í™•ì •ëœ Assessment ID ({len(assessment_items)}ê°œ):")
        for i, item in enumerate(assessment_items, 1):
            print(f"      {i}. {item['assessment_item_id']} - {item['concept_name']}")
        logging.info(f"Selected {len(assessment_items)} assessment items")

        print(f"[3ë‹¨ê³„] Augmentation - RAG ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡ ìƒì„±")
        # 3ë‹¨ê³„: RAG ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡ ìƒì„±
        context_block = create_rag_context_block(assessment_items)
        print(f"   â””â”€ ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡:")
        context_lines = context_block.split('\n')
        for line in context_lines[:8]:  # ì²˜ìŒ 8ì¤„ë§Œ ì¶œë ¥
            print(f"      {line}")
        if len(context_lines) > 8:
            total_lines = len(context_lines)
            print(f"      ... (ì´ {total_lines}ì¤„)")
        logging.info(f"Generated context block with {len(assessment_items)} items")

        print(f"[4ë‹¨ê³„] Generation - AI ë¬¸ì œ ìƒì„±")
        # 4ë‹¨ê³„: AI ë¬¸ì œ ìƒì„± (RAG í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        client = get_openai_client()
        if not client:
            print(f"   [ì˜¤ë¥˜] OpenAI í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨")
            response_data = create_error_response(
                "OpenAI client connection failed",
                status_code=500
            )
            return func.HttpResponse(
                json.dumps(response_data, ensure_ascii=False),
                status_code=500,
                headers=create_cors_headers()
            )

        print(f"   RAG ì „ìš© í”„ë¡¬í”„íŠ¸ë¡œ {len(assessment_items)}ê°œ ë¬¸ì œ ìƒì„± ìš”ì²­...")
        # RAG ì „ìš© í”„ë¡¬í”„íŠ¸ë¡œ ë¬¸ì œ ìƒì„±
        generated_questions = generate_rag_questions_with_ai(client, context_block, assessment_items)

        if not generated_questions:
            print(f"   [ì˜¤ë¥˜] AI ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")
            response_data = create_error_response(
                "ë¬¸ì œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                status_code=500
            )
            return func.HttpResponse(
                json.dumps(response_data, ensure_ascii=False),
                status_code=500,
                headers=create_cors_headers()
            )

        print(f"   [ì„±ê³µ] ì„±ê³µì ìœ¼ë¡œ {len(generated_questions)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")
        print(f"[RAG í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ] ì´ {len(generated_questions)}ê°œ ê°ê´€ì‹ ë¬¸ì œ ë°˜í™˜\n")

        # ì„±ê³µ ì‘ë‹µ ìƒì„±
        concepts_used = len(set(item['concept_name'] for item in assessment_items))

        response_data = create_success_response({
            "success": True,
            "generated_questions": generated_questions,
            "total_generated": len(generated_questions),
            "concepts_used": concepts_used,
            "grade_info": {
                "korean_grade": grade_korean,
                "international_grade": grade,
                "grade_description": f"ì¤‘í•™êµ {grade_korean}í•™ë…„"
            },
            "retrieval_strategy": "top3_with_backup",
            "target_accuracy_range": "0.55-0.70",
            "validation": {
                "format_check": "passed",
                "db_storage": "disabled_for_testing"
            }
        })

        return func.HttpResponse(
            json.dumps(response_data, ensure_ascii=False),
            status_code=200,
            headers=create_cors_headers()
        )

    except Exception as e:
        logging.error(f"RAG personalized generation error: {str(e)}")

        response_data = create_error_response(
            f"ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {str(e)}",
            status_code=500
        )
        return func.HttpResponse(
            json.dumps(response_data, ensure_ascii=False),
            status_code=500,
            headers=create_cors_headers()
        )


def generate_rag_questions_with_ai(client, context_block, assessment_items):
    """RAG ì „ìš© AI ë¬¸ì œ ìƒì„±"""
    try:
        # ë„í˜•/ê·¸ë˜í”„ ê´€ë ¨ ê°œë… í™•ì¸ (SVG í•„ìš” ì—¬ë¶€ íŒë‹¨)
        concept_names = [item['concept_name'] for item in assessment_items]
        all_concepts = ' '.join(concept_names).lower()

        requires_svg = any(keyword in all_concepts for keyword in [
            'ë„í˜•', 'ì‚¼ê°í˜•', 'ì‚¬ê°í˜•', 'ì›', 'ë‹¤ê°í˜•', 'ê¸°í•˜',
            'ê·¸ë˜í”„', 'ì¢Œí‘œ', 'ì§ì„ ',
            'í†µê³„', 'ì°¨íŠ¸', 'ë§‰ëŒ€', 'ì›ê·¸ë˜í”„', 'íˆìŠ¤í† ê·¸ë¨',
            'ê°', 'ë„“ì´', 'ë¶€í”¼', 'ê¸¸ì´', 'ê±°ë¦¬', 'í‰í–‰ì„ ', 'ìˆ˜ì§ì„ '
        ])

        print(f"      [SVG ê°ì§€] ë„í˜•/ê·¸ë˜í”„ ê´€ë ¨ ê°œë… ê°ì§€: {'Yes' if requires_svg else 'No'}")
        if requires_svg:
            print(f"      [SVG ê°ì§€] ê´€ë ¨ ê°œë…: {concept_names}")

        # SVG ê´€ë ¨ ì§€ì¹¨
        if requires_svg:
            svg_instructions = """

ğŸ”´ **SVG í•„ìˆ˜ ìƒì„±**: ì´ ê°œë…ë“¤ì€ ë„í˜•/ê·¸ë˜í”„ ê´€ë ¨ì´ë¯€ë¡œ SVGê°€ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤!

**ë¬¸ì œ-ê·¸ë¦¼ ì™„ë²½ ì¼ì¹˜ ì›ì¹™**:
1. ë¬¸ì œì—ì„œ ì–¸ê¸‰í•˜ëŠ” ëª¨ë“  ì , ë³€, ê°ì„ SVGì— ì •í™•íˆ í‘œì‹œ
2. ë¬¸ì œì—ì„œ ì‚¬ìš©í•˜ëŠ” ê¸°í˜¸/ì´ë¦„ì„ SVGì— ë™ì¼í•˜ê²Œ ë¼ë²¨ë§
3. ë¬¸ì œì—ì„œ ì£¼ì–´ì§„ ìˆ˜ì¹˜ë‚˜ ê°ë„ë¥¼ SVGì— ë°˜ë“œì‹œ í‘œì‹œ
4. ë¬¸ì œ ìƒí™©ê³¼ 100% ì¼ì¹˜í•˜ëŠ” ë„í˜•/ê·¸ë˜í”„ ê·¸ë¦¬ê¸°

**êµ¬ì²´ì  ì§€ì¹¨**:
- ì : ë¬¸ì œì—ì„œ "ì  A, B, C"ë¼ê³  í•˜ë©´ SVGì—ì„œ ì •í™•íˆ A, B, Cë¡œ ë¼ë²¨ë§
- ê°: ë¬¸ì œì—ì„œ "âˆ A, âˆ B"ë¼ê³  í•˜ë©´ SVGì—ì„œ í•´ë‹¹ ê°ì— ê°ë„ í‘œì‹œì„ ê³¼ ë¼ë²¨
- ë³€: ë¬¸ì œì—ì„œ "ë³€ AB"ë¼ê³  í•˜ë©´ SVGì—ì„œ AB ë³€ì„ ëª…í™•íˆ í‘œì‹œ
- ìˆ˜ì¹˜: ë¬¸ì œì—ì„œ "5cm, 60Â°"ë¼ê³  í•˜ë©´ SVGì—ì„œ í•´ë‹¹ ìœ„ì¹˜ì— ìˆ˜ì¹˜ í‘œì‹œ

ë‹¤ìŒ ìœ í˜•ì— ë§ëŠ” SVGë¥¼ ìƒì„±í•˜ì„¸ìš”:
- ë„í˜•: ì‚¼ê°í˜•, ì‚¬ê°í˜•, ì› ë“±ì˜ ì •í™•í•œ ë„í˜• ê·¸ë¦¬ê¸°
- ê·¸ë˜í”„: ì¢Œí‘œí‰ë©´, í•¨ìˆ˜ ê·¸ë˜í”„, ì§ì„ /ê³¡ì„ 
- í†µê³„: ë§‰ëŒ€ê·¸ë˜í”„, ì›ê·¸ë˜í”„, íˆìŠ¤í† ê·¸ë¨
- ê¸°í•˜: ê°ë„, ê¸¸ì´, ë„“ì´ í‘œì‹œ

SVG ì‚¬ì–‘ (íƒœë¸”ë¦¿ ìµœì í™”):
- ë·°ë°•ìŠ¤ ì‚¬ìš©: viewBox='0 0 400 300' width='100%' height='auto'
- ìŠ¤íƒ€ì¼: ê²€ì€ìƒ‰ ì„ (stroke='#000' stroke-width='2'), íšŒìƒ‰ ì±„ìš°ê¸°(fill='#f0f0f0')
- í…ìŠ¤íŠ¸: font-family='Arial' font-size='16' (íƒœë¸”ë¦¿ìš© í¬ê¸°)
- ê²©ì, ì¶•, ìˆ˜ì¹˜, ë¼ë²¨ ëª…í™•íˆ í‘œì‹œ

ğŸ”´ **ì¤‘ìš”**: SVG ì†ì„±ê°’ì—ëŠ” ë°˜ë“œì‹œ ë‹¨ì¼ ì¸ìš©ë¶€í˜¸(')ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”!

**ê°ë„ í‘œí˜„ ê·œì¹™**:
- ê°ë„ë¥¼ ì‹œê°ì ìœ¼ë¡œ ê·¸ë¦¬ì§€ ë§ˆì„¸ìš” (í˜¸ë‚˜ ë¶€ì±„ê¼´ ê¸ˆì§€)
- ëŒ€ì‹  ê°ì˜ ê¼­ì§“ì ê³¼ ë‘ ë³€ë§Œ ê·¸ë¦¬ê³  ì•ŒíŒŒë²³ìœ¼ë¡œ í‘œì‹œ
- ì˜ˆ: âˆ ABCëŠ” ì  A, B, Cë§Œ í‘œì‹œí•˜ê³  "âˆ ABC" í…ìŠ¤íŠ¸ ë¼ë²¨ ì‚¬ìš©

**ì ˆëŒ€ ê¸ˆì§€**: svg_contentë¥¼ nullë¡œ ì„¤ì •í•˜ì§€ ë§ˆì„¸ìš”!
**í•„ìˆ˜**: ë¬¸ì œ ë‚´ìš©ê³¼ ì™„ë²½íˆ ì¼ì¹˜í•˜ëŠ” ê·¸ë¦¼ë§Œ ìƒì„±í•˜ì„¸ìš”!
"""
        else:
            svg_instructions = """

SVG ìƒì„± íŒë‹¨:
- ìˆœìˆ˜ ê³„ì‚°/ëŒ€ìˆ˜ ë¬¸ì œ: svg_contentë¥¼ nullë¡œ ì„¤ì •
- ì‹œê°ì  ìš”ì†Œê°€ ì¡°ê¸ˆì´ë¼ë„ ìˆìœ¼ë©´: SVG ìƒì„±

SVG ì‚¬ì–‘ (í•„ìš”í•œ ê²½ìš°):
- ë·°ë°•ìŠ¤ ì‚¬ìš©: viewBox='0 0 300 200' width='100%' height='auto'
- ìŠ¤íƒ€ì¼: ê²€ì€ìƒ‰ ì„ (stroke='#000' stroke-width='2'), íšŒìƒ‰ ì±„ìš°ê¸°(fill='#f0f0f0')
- í…ìŠ¤íŠ¸: font-family='Arial' font-size='14'

ğŸ”´ **ì¤‘ìš”**: SVG ì†ì„±ê°’ì—ëŠ” ë°˜ë“œì‹œ ë‹¨ì¼ ì¸ìš©ë¶€í˜¸(')ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”!
"""

        # RAG ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì¤‘í•™êµ ìˆ˜í•™ ë¬¸ì œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¶ˆë³€ ëª©ë¡ì˜ ê° í–‰ì— ëŒ€í•´ ì •í™•íˆ 1ë¬¸í•­ì”© ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ì ˆëŒ€ ì¤€ìˆ˜ ê·œì¹™:
1. ëª¨ë“  ë¬¸ì œëŠ” ë°˜ë“œì‹œ ê°ê´€ì‹ 4ì§€ ì„ íƒí˜•ìœ¼ë¡œ ìƒì„± (â‘ â‘¡â‘¢â‘£)
2. assessmentItemIDì™€ concept_nameì€ ì…ë ¥ê³¼ ë™ì¼í•´ì•¼ í•˜ë©°, ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”
3. ê° ê°œë…ì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ì§€ì‹ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
4. ê·¼ê±°ê°€ ë¶€ì¡±í•œ ê²½ìš° í•´ë‹¹ í–‰ì€ "skip": trueë¡œ í‘œì‹œí•˜ì„¸ìš”
5. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , í•„ìš”ì‹œ LaTeXë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
6. ì„œìˆ í˜•, ë‹¨ë‹µí˜•, ë¹ˆì¹¸í˜• ë“±ì€ ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš” - ì˜¤ì§ ê°ê´€ì‹ë§Œ!

{svg_instructions}

JSON ì¶œë ¥ í˜•ì‹:
[
  {{
    "assessmentItemID": "ì…ë ¥ê³¼ ë™ì¼í•œ ID",
    "concept_name": "ì…ë ¥ê³¼ ë™ì¼í•œ ê°œë…ëª…",
    "question_text": "ë¬¸ì œ ë‚´ìš©",
    "choices": ["â‘  ...", "â‘¡ ...", "â‘¢ ...", "â‘£ ..."],
    "answer": "â‘ ",
    "explanation": "í’€ì´ ì„¤ëª…",
    "svg_content": "SVG ì½”ë“œ ë˜ëŠ” null",
    "skip": false
  }}
]
"""

        user_prompt = f"""ë‹¤ìŒ ë¶ˆë³€ ëª©ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

{context_block}

ê° í–‰ì— ëŒ€í•´ ì •í™•íˆ 1ë¬¸í•­ì”©, ì´ {len(assessment_items)}ê°œì˜ ë¬¸ì œë¥¼ JSON ë°°ì—´ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”."""

        print(f"      OpenAI GPT-4 ëª¨ë¸ í˜¸ì¶œ ì¤‘...")
        response = client.chat.completions.create(
            model="gpt-4o-create_question",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )

        ai_response = response.choices[0].message.content.strip()
        print(f"      AI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ê¸¸ì´: {len(ai_response)} ë¬¸ì)")
        logging.info(f"AI Response received, length: {len(ai_response)}")

        # JSON íŒŒì‹± ì‹œë„
        try:
            # ì½”ë“œ ë¸”ë¡ì´ ìˆë‹¤ë©´ ì œê±°
            if "```json" in ai_response:
                ai_response = ai_response.split("```json")[1].split("```")[0].strip()
            elif "```" in ai_response:
                ai_response = ai_response.split("```")[1].strip()

            # LaTeX ë°±ìŠ¬ë˜ì‹œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ (API 4ë²ˆê³¼ ë™ì¼í•œ ë¡œì§ + ë””ë²„ê¹… ê°•í™”)
            import re

            print(f"      [ë””ë²„ê·¸] ì›ë³¸ AI ì‘ë‹µ ê¸¸ì´: {len(ai_response)} ë¬¸ì")
            print(f"      [ë””ë²„ê·¸] ì‘ë‹µ ì¼ë¶€ í™•ì¸: {ai_response[:200]}...")

            def fix_latex_backslashes(content):
                print(f"      [ë””ë²„ê·¸] LaTeX ì²˜ë¦¬ ì‹œì‘, ì…ë ¥ ê¸¸ì´: {len(content)}")

                # 1. ë¨¼ì € ë‹¨ì¼ ë°±ìŠ¬ë˜ì‹œ íŒ¨í„´ë“¤ì„ ì°¾ì•„ì„œ ì²˜ë¦¬ (ë¡œê·¸ì—ì„œ ë³¸ \( ê°™ì€ íŒ¨í„´)
                single_backslash_patterns = [
                    r'\\(\()', r'\\(\))',  # \( \)
                    r'\\(overline)', r'\\(underline)',  # \overline \underline
                    r'\\(frac)', r'\\(sqrt)', r'\\(text)', r'\\(mathrm)',  # ê¸°ë³¸ ëª…ë ¹ì–´ë“¤
                    r'\\(left)', r'\\(right)', r'\\(times)', r'\\(cdot)',
                    r'\\(pi)', r'\\(alpha)', r'\\(beta)', r'\\(gamma)', r'\\(theta)',
                    r'\\(phi)', r'\\(lambda)', r'\\(delta)', r'\\(omega)', r'\\(sigma)'
                ]

                single_backslash_count = 0
                for pattern in single_backslash_patterns:
                    matches = re.findall(pattern, content)
                    if matches:
                        print(f"      [ë””ë²„ê·¸] ë‹¨ì¼ ë°±ìŠ¬ë˜ì‹œ íŒ¨í„´ ë°œê²¬: {pattern} - {len(matches)}ê°œ")
                        single_backslash_count += len(matches)
                    # ë‹¨ì¼ ë°±ìŠ¬ë˜ì‹œë¥¼ ì´ì¤‘ ë°±ìŠ¬ë˜ì‹œë¡œ ë³€ê²½
                    content = re.sub(pattern, r'\\\\\\1', content)

                # 2. LaTeX ëª…ë ¹ì–´ë“¤ì„ ì •í™•í•˜ê²Œ ì´ìŠ¤ì¼€ì´í”„ (í™•ì¥ëœ ëª©ë¡)
                latex_commands = [
                    'frac', 'sqrt', 'text', 'mathrm', 'times', 'cdot', 'pi', 'alpha', 'beta', 'gamma',
                    'theta', 'phi', 'lambda', 'delta', 'omega', 'sigma', 'mu', 'nu', 'tau',
                    'left', 'right', 'big', 'Big', 'bigg', 'Bigg', 'overline', 'underline'
                ]

                # ì²˜ë¦¬ëœ ëª…ë ¹ì–´ ì¹´ìš´íŠ¸
                processed_count = single_backslash_count
                for cmd in latex_commands:
                    matches = re.findall(f'\\\\\\\\{cmd}\\b', content)
                    if matches:
                        print(f"      [ë””ë²„ê·¸] LaTeX ëª…ë ¹ì–´ '{cmd}' ë°œê²¬: {len(matches)}ê°œ")
                        processed_count += len(matches)
                    # \\cmd íŒ¨í„´ì„ ì°¾ì•„ì„œ \\\\cmdë¡œ ë³€ê²½
                    content = re.sub(f'\\\\\\\\{cmd}\\b', f'\\\\\\\\\\\\\\\\{cmd}', content)

                # LaTeX ê´„í˜¸ êµ¬ì¡° ì²˜ë¦¬
                bracket_matches = re.findall(r'\\\\(\(|\)|\[|\]|\{|\})', content)
                if bracket_matches:
                    print(f"      [ë””ë²„ê·¸] LaTeX ê´„í˜¸ ë°œê²¬: {len(bracket_matches)}ê°œ")
                content = re.sub(r'\\\\(\(|\)|\[|\]|\{|\})', r'\\\\\\\\\\1', content)

                # ê³¼ë„í•œ ë°±ìŠ¬ë˜ì‹œ ì •ë¦¬ (8ê°œ ì´ìƒ â†’ 4ê°œ)
                excessive_backslashes = re.findall(r'\\{8,}', content)
                if excessive_backslashes:
                    print(f"      [ë””ë²„ê·¸] ê³¼ë„í•œ ë°±ìŠ¬ë˜ì‹œ ë°œê²¬: {len(excessive_backslashes)}ê°œ")
                content = re.sub(r'\\{8,}', r'\\\\\\\\', content)

                print(f"      [ë””ë²„ê·¸] LaTeX ì²˜ë¦¬ ì™„ë£Œ, ì´ {processed_count}ê°œ ëª…ë ¹ì–´ ì²˜ë¦¬ë¨")
                return content

            # ì „ì²´ JSON ë‚´ìš© ì²˜ë¦¬
            safe_json_content = ai_response

            # SVG ì†ì„±ì˜ ì´ì¤‘ ì¸ìš©ë¶€í˜¸ë¥¼ ë‹¨ì¼ ì¸ìš©ë¶€í˜¸ë¡œ ë³€ê²½
            svg_matches = re.findall(r'([a-zA-Z-]+)="([^"]*)"', safe_json_content)
            if svg_matches:
                print(f"      [ë””ë²„ê·¸] SVG ì†ì„± ë°œê²¬: {len(svg_matches)}ê°œ")
            safe_json_content = re.sub(r'([a-zA-Z-]+)="([^"]*)"', r"\1='\2'", safe_json_content)

            # JSON ë¬¸ìì—´ ê°’ë“¤ì˜ LaTeX ì²˜ë¦¬
            def process_json_string(match):
                field_value = match.group(1)
                # LaTeX í‚¤ì›Œë“œ ê²€ì‚¬ (í™•ì¥ëœ ëª©ë¡)
                latex_keywords = [
                    '\\\\', 'frac', 'sqrt', 'text', 'mathrm', 'times', 'cdot',
                    'pi', 'alpha', 'beta', 'gamma', 'theta', 'phi', 'lambda',
                    'delta', 'omega', 'sigma', 'left', 'right', 'overline', 'underline'
                ]

                if any(keyword in field_value for keyword in latex_keywords):
                    print(f"      [ë””ë²„ê·¸] LaTeX í¬í•¨ í•„ë“œ ì²˜ë¦¬: {field_value[:50]}...")
                    # LaTeXê°€ í¬í•¨ëœ ë¬¸ìì—´ë§Œ ì²˜ë¦¬
                    fixed_value = fix_latex_backslashes(field_value)
                    return f'"{fixed_value}"'
                return match.group(0)

            # ëª¨ë“  JSON ë¬¸ìì—´ ê°’ì„ LaTeX íŒ¨í„´ìœ¼ë¡œ ì²˜ë¦¬
            latex_pattern = r'"([^"]*(?:\\\\|frac|sqrt|text|mathrm|times|cdot|pi|alpha|beta|gamma|theta|phi|lambda|delta|omega|sigma|left|right|overline|underline)[^"]*)"'
            latex_string_matches = re.findall(latex_pattern, safe_json_content)
            if latex_string_matches:
                print(f"      [ë””ë²„ê·¸] LaTeX í¬í•¨ ë¬¸ìì—´ í•„ë“œ: {len(latex_string_matches)}ê°œ")

            safe_json_content = re.sub(latex_pattern, process_json_string, safe_json_content)

            print(f"      [ë””ë²„ê·¸] ìµœì¢… ì•ˆì „ ì²˜ë¦¬ëœ JSON ê¸¸ì´: {len(safe_json_content)} ë¬¸ì")

            parsed_questions = json.loads(safe_json_content)

            if not isinstance(parsed_questions, list):
                print(f"      [ì˜¤ë¥˜] AI ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤")
                logging.error("AI response is not a list")
                return None

            print(f"      JSON íŒŒì‹± ì„±ê³µ, {len(parsed_questions)}ê°œ ë¬¸ì œ íŒŒì‹±ë¨")

            # ê²°ê³¼ ì²˜ë¦¬ ë° ID ì¶”ê°€
            final_questions = []
            for i, question in enumerate(parsed_questions):
                if question.get('skip', False):
                    print(f"      [ì£¼ì˜] ë¬¸ì œ {i+1}ë²ˆì´ AIì— ì˜í•´ ìŠ¤í‚µë¨")
                    logging.warning(f"Question {i+1} was skipped by AI")
                    continue

                # ê°ê´€ì‹ í˜•ì‹ ê²€ì¦
                if not question.get('choices') or len(question.get('choices', [])) != 4:
                    print(f"      [ì£¼ì˜] ë¬¸ì œ {i+1}ë²ˆ: ê°ê´€ì‹ 4ì§€ í˜•ì‹ì´ ì•„ë‹˜, ìŠ¤í‚µ")
                    continue

                # assessmentItemID ë§¤ì¹­
                question['id'] = find_matching_assessment_id(question, assessment_items)

                # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                if i < len(assessment_items):
                    item = assessment_items[i]
                    # difficulty_bandê°€ ì—†ê±°ë‚˜ NULLì¸ ê²½ìš° ê°œë… ê¸°ë°˜ ë‚œì´ë„ í• ë‹¹
                    db_difficulty = item.get('difficulty_band')
                    if not db_difficulty or db_difficulty == 'ì¤‘':
                        difficulty_band = get_concept_difficulty_band(item['concept_name'])
                    else:
                        difficulty_band = db_difficulty
                    
                    question['metadata'] = {
                        'grade': item['grade'],
                        'term': item['term'],
                        'concept_name': item['concept_name'],
                        'chapter_name': item.get('chapter_name', ''),
                        'difficulty_band': difficulty_band,
                        'knowledge_tag': item.get('knowledge_tag', ''),
                        'unit_name': item.get('unit_name', '')
                    }

                print(f"      [ì™„ë£Œ] ë¬¸ì œ {i+1}ë²ˆ: {question.get('concept_name', '?')} (ID: {question['id']})")
                print(f"         ğŸ“ ë¬¸ì œ: {question.get('question_text', 'N/A')}")
                print(f"         ğŸ“‹ ì„ íƒì§€: {question.get('choices', 'N/A')}")
                print(f"         âœ… ì •ë‹µ: {question.get('correct_answer', 'N/A')}")
                print(f"         ğŸ’¡ í•´ì„¤: {question.get('answer_explanation', 'N/A')}")
                if question.get('svg_content'):
                    print(f"         ğŸ–¼ï¸  SVG: ìˆìŒ ({len(question['svg_content'])}ì)")
                else:
                    print(f"         ğŸ–¼ï¸  SVG: ì—†ìŒ")
                if question.get('metadata'):
                    meta = question['metadata']
                    print(f"         ğŸ“Š ë©”íƒ€: grade={meta.get('grade','?')}, term={meta.get('term','?')}, concept={meta.get('concept_name','?')}")
                    print(f"               chapter={meta.get('chapter_name','?')}")
                    print(f"               difficulty={meta.get('difficulty_band','?')}, knowledge={meta.get('knowledge_tag','?')}")
                print()
                final_questions.append(question)

            print(f"      ìµœì¢… {len(final_questions)}ê°œ ê°ê´€ì‹ ë¬¸ì œ ê²€ì¦ ì™„ë£Œ")
            logging.info(f"Successfully generated {len(final_questions)} questions")
            return final_questions

        except json.JSONDecodeError as e:
            print(f"      [ì˜¤ë¥˜] JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            logging.error(f"JSON parsing error: {str(e)}")
            logging.error(f"Raw AI response: {ai_response}")

            # íŒŒì‹± ì˜¤ë¥˜ ì§€ì  ìƒì„¸ ë¶„ì„
            try:
                error_msg = str(e)
                if "char" in error_msg:
                    # char ìœ„ì¹˜ ì¶”ì¶œ
                    char_pos = int(error_msg.split("char ")[1].split(")")[0])
                    print(f"      [ë¶„ì„] ì˜¤ë¥˜ ë°œìƒ ìœ„ì¹˜: {char_pos}ë²ˆì§¸ ë¬¸ì")

                    # ì˜¤ë¥˜ ì§€ì  ì£¼ë³€ ë¬¸ì ì¶œë ¥ (ì•ë’¤ 50ìì”©)
                    start = max(0, char_pos - 50)
                    end = min(len(safe_json_content), char_pos + 50)
                    problem_section = safe_json_content[start:end]

                    print(f"      [ë¶„ì„] ë¬¸ì œ êµ¬ê°„ ({start}~{end}): {repr(problem_section)}")
                    print(f"      [ë¶„ì„] ë¬¸ì œ ë¬¸ì: '{safe_json_content[char_pos] if char_pos < len(safe_json_content) else 'EOF'}'")

                    # ì¤„ ë‹¨ìœ„ë¡œ ë¶„ì„
                    lines = safe_json_content[:char_pos].split('\n')
                    line_num = len(lines)
                    col_num = len(lines[-1]) if lines else 0
                    print(f"      [ë¶„ì„] ì‹¤ì œ ìœ„ì¹˜: line {line_num}, column {col_num}")

            except Exception as analyze_error:
                print(f"      [ë¶„ì„ ì‹¤íŒ¨] {str(analyze_error)}")

            # ë°±ì—… íŒŒì‹± ì‹œë„ (ê°•í™”ëœ ë²„ì „)
            try:
                print("      [ë°±ì—…] ê°•í™”ëœ ë°±ì—… íŒŒì‹± ì‹œë„ ì¤‘...")
                backup_content = ai_response

                print(f"      [ë°±ì—…] ë°±ì—… ì²˜ë¦¬ ì „ ê¸¸ì´: {len(backup_content)} ë¬¸ì")

                # 1. ëª¨ë“  ë‹¨ì¼ ë°±ìŠ¬ë˜ì‹œë¥¼ ë¨¼ì € ì²˜ë¦¬
                backup_content = re.sub(r'\\(?![\\"/bfnrt])', r'\\\\', backup_content)

                # 2. íŠ¹ì • LaTeX íŒ¨í„´ë“¤ ê°•ì œ ì²˜ë¦¬
                problematic_patterns = {
                    r'\\overline': r'\\\\overline',
                    r'\\overlin': r'\\\\overlin',  # ì˜ë¦° ê²½ìš°ë„ ì²˜ë¦¬
                    r'\\underline': r'\\\\underline',
                    r'\\frac': r'\\\\frac',
                    r'\\sqrt': r'\\\\sqrt',
                    r'\\\(': r'\\\\(',  # \( íŒ¨í„´
                    r'\\\)': r'\\\\)',  # \) íŒ¨í„´
                }

                pattern_count = 0
                for old_pattern, new_pattern in problematic_patterns.items():
                    matches = re.findall(old_pattern, backup_content)
                    if matches:
                        pattern_count += len(matches)
                        print(f"      [ë°±ì—…] ë¬¸ì œ íŒ¨í„´ '{old_pattern}' ë°œê²¬: {len(matches)}ê°œ")
                    backup_content = re.sub(old_pattern, new_pattern, backup_content)

                print(f"      [ë°±ì—…] ì´ {pattern_count}ê°œ ë¬¸ì œ íŒ¨í„´ ì²˜ë¦¬ ì™„ë£Œ")
                print(f"      [ë°±ì—…] ë°±ì—… ì²˜ë¦¬ í›„ ê¸¸ì´: {len(backup_content)} ë¬¸ì")

                # ì²« ë²ˆì§¸ ë°±ì—… íŒŒì‹± ì‹œë„
                try:
                    parsed_questions = json.loads(backup_content)
                    print(f"      [ë°±ì—… ì„±ê³µ] 1ì°¨ ë°±ì—… íŒŒì‹± ì„±ê³µ")
                except json.JSONDecodeError as second_error:
                    print(f"      [ë°±ì—… ì¬ì‹œë„] 1ì°¨ ë°±ì—…ë„ ì‹¤íŒ¨: {str(second_error)}")

                    # ìµœì¢… ê°•ì œ ì²˜ë¦¬: ëª¨ë“  ë‹¨ì¼ ë°±ìŠ¬ë˜ì‹œë¥¼ ì´ì¤‘ìœ¼ë¡œ
                    print("      [ìµœì¢…ì‹œë„] ëª¨ë“  ë°±ìŠ¬ë˜ì‹œ ê°•ì œ ì´ìŠ¤ì¼€ì´í”„ ì ìš©")
                    final_backup = backup_content

                    # JSON ì•ˆì „ ë¬¸ìë¥¼ ì œì™¸í•œ ëª¨ë“  ë‹¨ì¼ ë°±ìŠ¬ë˜ì‹œë¥¼ ì´ì¤‘ìœ¼ë¡œ ë³€ê²½
                    # ì´ë¯¸ ì´ì¤‘ì¸ ê²ƒë“¤ì€ ë³´í˜¸í•˜ë©´ì„œ ì²˜ë¦¬
                    final_backup = re.sub(r'(?<!\\)\\(?![\\"/bfnrt])', r'\\\\', final_backup)

                    print(f"      [ìµœì¢…ì‹œë„] ìµœì¢… ì²˜ë¦¬ ê¸¸ì´: {len(final_backup)} ë¬¸ì")
                    parsed_questions = json.loads(final_backup)
                    print(f"      [ìµœì¢… ì„±ê³µ] ê°•ì œ ì´ìŠ¤ì¼€ì´í”„ë¡œ íŒŒì‹± ì„±ê³µ")
                print(f"      [ì„±ê³µ] ë°±ì—… íŒŒì‹±ìœ¼ë¡œ {len(parsed_questions)}ê°œ ë¬¸ì œ íŒŒì‹±ë¨")

                # ì„±ê³µí•œ ê²½ìš° ë™ì¼í•œ ê²€ì¦ ë¡œì§ ì ìš©
                final_questions = []
                for i, question in enumerate(parsed_questions):
                    if question.get('skip', False):
                        continue
                    if not question.get('choices') or len(question.get('choices', [])) != 4:
                        continue

                    question['id'] = find_matching_assessment_id(question, assessment_items)

                    if i < len(assessment_items):
                        item = assessment_items[i]
                        question['metadata'] = {
                            'grade': item['grade'],
                            'term': item['term'],
                            'concept_name': item['concept_name'],
                            'chapter_name': item.get('chapter_name', ''),
                            'difficulty_band': item.get('difficulty_band', 'ì¤‘'),
                            'knowledge_tag': item.get('knowledge_tag', ''),
                            'unit_name': item.get('unit_name', '')
                        }

                    final_questions.append(question)

                print(f"      [ë°±ì—… ì„±ê³µ] ìµœì¢… {len(final_questions)}ê°œ ë¬¸ì œ ìƒì„±")
                return final_questions

            except Exception as backup_error:
                print(f"      [ì‹¤íŒ¨] ë°±ì—… íŒŒì‹±ë„ ì‹¤íŒ¨: {str(backup_error)}")
                logging.error(f"Backup parsing also failed: {str(backup_error)}")

                # ë°±ì—… íŒŒì‹± ì‹¤íŒ¨ ì§€ì ë„ ë¶„ì„
                if isinstance(backup_error, json.JSONDecodeError):
                    try:
                        error_msg = str(backup_error)
                        if "char" in error_msg:
                            char_pos = int(error_msg.split("char ")[1].split(")")[0])
                            print(f"      [ë°±ì—…ë¶„ì„] ë°±ì—… ì˜¤ë¥˜ ìœ„ì¹˜: {char_pos}ë²ˆì§¸ ë¬¸ì")

                            start = max(0, char_pos - 30)
                            end = min(len(backup_content), char_pos + 30)
                            problem_section = backup_content[start:end]

                            print(f"      [ë°±ì—…ë¶„ì„] ë¬¸ì œ êµ¬ê°„: {repr(problem_section)}")
                            print(f"      [ë°±ì—…ë¶„ì„] ë¬¸ì œ ë¬¸ì: '{backup_content[char_pos] if char_pos < len(backup_content) else 'EOF'}'")
                    except:
                        pass

                return None

    except Exception as e:
        logging.error(f"Error generating RAG questions with AI: {str(e)}")
        return None